{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b66b54b6-571d-474a-bb63-00b9bc05d8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yt-dlp in /opt/anaconda3/lib/python3.12/site-packages (2025.4.30)\n",
      "Requirement already satisfied: openai-whisper in /opt/anaconda3/lib/python3.12/site-packages (20240930)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.7.1)\n",
      "Requirement already satisfied: more-itertools in /opt/anaconda3/lib/python3.12/site-packages (from openai-whisper) (10.3.0)\n",
      "Requirement already satisfied: numba in /opt/anaconda3/lib/python3.12/site-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from openai-whisper) (1.26.4)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/lib/python3.12/site-packages (from openai-whisper) (0.9.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from openai-whisper) (4.66.5)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/anaconda3/lib/python3.12/site-packages (from numba->openai-whisper) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tiktoken->openai-whisper) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install yt-dlp openai-whisper torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a398b64a-a7bd-41c2-9e4e-272eab5057fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yt_dlp\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602bf88d-2a44-4def-8b18-9475780e37b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# STEP 1: Download audio from YouTube\n",
    "# ------------------------------\n",
    "def download_audio(youtube_url, output_path=\"audio.mp3\"):\n",
    "    ydl_opts = {\n",
    "        \"format\": \"bestaudio/best\",\n",
    "        \"outtmpl\": \"temp.%(ext)s\",\n",
    "        \"postprocessors\": [\n",
    "            {\n",
    "                \"key\": \"FFmpegExtractAudio\",\n",
    "                \"preferredcodec\": \"mp3\",\n",
    "                \"preferredquality\": \"192\",\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([youtube_url])\n",
    "\n",
    "    # Rename downloaded file to fixed name\n",
    "    for f in os.listdir(\".\"):\n",
    "        if f.startswith(\"temp\") and f.endswith(\".mp3\"):\n",
    "            os.rename(f, output_path)\n",
    "            break\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b29952a-3f84-4805-8d10-db7bb6bdb881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# STEP 2: Transcribe audio using Whisper\n",
    "# ------------------------------\n",
    "def transcribe_audio(audio_path, model_size=\"base\", output_file=\"transcript.txt\"):\n",
    "    print(f\"Loading Whisper model ({model_size})...\")\n",
    "    model = whisper.load_model(model_size)\n",
    "\n",
    "    print(\"Transcribing...\")\n",
    "    result = model.transcribe(audio_path)\n",
    "\n",
    "    # Save transcription\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(result[\"text\"])\n",
    "\n",
    "    print(f\"✅ Transcription saved to {output_file}\")\n",
    "    return result[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a092e15-021f-46d7-a4a2-74c12ac45381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/shorts/RgaWpx87fJg?feature=share\n",
      "[youtube] RgaWpx87fJg: Downloading webpage\n",
      "[youtube] RgaWpx87fJg: Downloading tv client config\n",
      "[youtube] RgaWpx87fJg: Downloading tv player API JSON\n",
      "[youtube] RgaWpx87fJg: Downloading ios player API JSON\n",
      "[youtube] RgaWpx87fJg: Downloading m3u8 information\n",
      "[info] RgaWpx87fJg: Downloading 1 format(s): 251\n",
      "[download] Destination: temp.webm\n",
      "[download] 100% of    1.10MiB in 00:00:00 at 1.14MiB/s   \n",
      "[ExtractAudio] Destination: temp.mp3\n",
      "Deleting original file temp.webm (pass -k to keep)\n",
      "Loading Whisper model (base)...\n",
      "Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Transcription saved to transcript.txt\n",
      "\n",
      "Sample Transcript (first 500 chars):\n",
      "\n",
      " What are the first words you should say in a speech? And what are the last words you should say in a speech? I guarantee if you go to conferences, 19 out of 20 speakers will start in one of these ways. Number one, my name is Conor Neal, I'm from Tango and this talk is about the latest trend in monitoring strategies. All of you are sitting with a piece of paper in front of you that says, I'm Conor Neal, I've come from Ireland and I'm going to talk about Tango zero four and this. So by repeating \n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# STEP 3: Run the pipeline\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    YOUTUBE_URL = \"https://www.youtube.com/shorts/RgaWpx87fJg?feature=share\"  # replace with your link\n",
    "\n",
    "    audio_file = download_audio(YOUTUBE_URL, \"audio.mp3\")\n",
    "    transcription = transcribe_audio(audio_file, model_size=\"base\", output_file=\"transcript.txt\")\n",
    "\n",
    "    print(\"\\nSample Transcript (first 500 chars):\\n\")\n",
    "    print(transcription[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4150a881-4b9a-41f6-a198-d59488b7bc57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
