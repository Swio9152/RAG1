# -*- coding: utf-8 -*-
"""YT_transcription.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y7YTNxvaYspXjBj490_U3aAR0mY-ekLS
"""

!pip install yt-dlp openai-whisper torch

import os
import yt_dlp
import whisper

# ------------------------------
# STEP 1: Download audio from YouTube
# ------------------------------
def download_audio(youtube_url, output_path="audio.mp3"):
    ydl_opts = {
        "format": "bestaudio/best",
        "outtmpl": "temp.%(ext)s",
        "postprocessors": [
            {
                "key": "FFmpegExtractAudio",
                "preferredcodec": "mp3",
                "preferredquality": "192",
            }
        ],
    }

    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        ydl.download([youtube_url])

    # Rename downloaded file to fixed name
    for f in os.listdir("."):
        if f.startswith("temp") and f.endswith(".mp3"):
            os.rename(f, output_path)
            break
    return output_path

# ------------------------------
# STEP 2: Transcribe audio using Whisper
# ------------------------------
def transcribe_audio(audio_path, model_size="base", output_file="transcript.txt"):
    print(f"Loading Whisper model ({model_size})...")
    model = whisper.load_model(model_size)

    print("Transcribing...")
    result = model.transcribe(audio_path)

    # Save transcription
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(result["text"])

    print(f"âœ… Transcription saved to {output_file}")
    return result["text"]

# ------------------------------
# STEP 3: Run the pipeline
# ------------------------------
if __name__ == "__main__":
    YOUTUBE_URL = "https://www.youtube.com/shorts/RgaWpx87fJg?feature=share"  # replace with your link

    audio_file = download_audio(YOUTUBE_URL, "audio.mp3")
    transcription = transcribe_audio(audio_file, model_size="base", output_file="transcript.txt")

    print("\nSample Transcript (first 500 chars):\n")
    print(transcription[:500])

